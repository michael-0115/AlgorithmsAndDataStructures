{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Single-link clustering with Kruskal’s algorithm\n",
    "* All the code are written in Python 3.0 in jupyter notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the package needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from bokeh.models import Label\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.charts import Scatter, show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Using the ADT class for points in 2-dimensional Euclidean space from before, implement a function to generate a test set of n random nodes/points, where n is a user-definable parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each points with its ID:\n",
      "{0: (1022, 1697), 1: (149, 1510), 2: (1251, 1242), 3: (50, 1301), 4: (1776, 604), 5: (1103, 1980), 6: (1573, 1282), 7: (756, 829), 8: (1158, 1696), 9: (898, 72), 10: (1122, 1176), 11: (570, 644), 12: (1213, 1092), 13: (268, 860), 14: (845, 1154), 15: (857, 64), 16: (1655, 400), 17: (1079, 1120), 18: (1001, 483), 19: (608, 982), 20: (1641, 650), 21: (1091, 890), 22: (1481, 1135), 23: (1597, 240), 24: (1204, 364), 25: (855, 369), 26: (405, 325), 27: (1401, 835), 28: (1610, 90), 29: (180, 1027), 30: (392, 1677), 31: (624, 1014), 32: (1365, 109), 33: (762, 976), 34: (1561, 1028), 35: (699, 1084), 36: (1046, 520), 37: (1628, 519), 38: (1649, 1223), 39: (1293, 614), 40: (1662, 1982), 41: (952, 169), 42: (1890, 1578), 43: (660, 713), 44: (1016, 220), 45: (924, 1711), 46: (1288, 905), 47: (1770, 732), 48: (272, 1887), 49: (533, 1985), 50: (1864, 572), 51: (254, 259), 52: (1157, 817), 53: (691, 1097), 54: (833, 1490), 55: (292, 755), 56: (1896, 1943), 57: (862, 1006), 58: (1789, 394), 59: (975, 1969), 60: (1986, 41), 61: (364, 1170), 62: (1457, 714), 63: (1391, 688), 64: (252, 106), 65: (1484, 493), 66: (1294, 456), 67: (51, 1906), 68: (114, 668), 69: (1502, 1197), 70: (1647, 1124), 71: (1843, 1069), 72: (851, 1114), 73: (188, 1815), 74: (1680, 110), 75: (382, 1332), 76: (1217, 891), 77: (1505, 1714), 78: (1633, 1052), 79: (1740, 1152), 80: (250, 1785), 81: (1958, 826), 82: (904, 486), 83: (1384, 1709), 84: (261, 1368), 85: (673, 1366), 86: (945, 1), 87: (153, 421), 88: (1857, 151), 89: (860, 1800), 90: (579, 1706), 91: (1313, 769), 92: (456, 1872), 93: (956, 258), 94: (359, 113), 95: (283, 1801), 96: (744, 1235), 97: (1803, 1416), 98: (707, 44), 99: (1442, 206)}\n"
     ]
    }
   ],
   "source": [
    "#ADT class for point set:\n",
    "class Points: \n",
    "   \n",
    "    def __init__(self):\n",
    "        #create a empty dictionary \n",
    "        self.pointSet = {}\n",
    "        \n",
    "    def addPoint(self, key, p):\n",
    "        #add point with points' ID to dictionary with \n",
    "        self.pointSet[key] = (p)\n",
    "        \n",
    "    def getPoint(self,key):    \n",
    "        #get point from dictionary \n",
    "        return self.pointSet[key]\n",
    "\n",
    "    def getPointSet(self):\n",
    "        #get all points with points ID\n",
    "        return self.pointSet\n",
    "    \n",
    "    def getPointKeys(self):\n",
    "        #get all points' ID\n",
    "        return list(self.pointSet)\n",
    "    \n",
    "    def euclidean_distance(self, p1Key, p2Key):\n",
    "        #get Euclidean distance of two points\n",
    "        xdiff = self.pointSet[p1Key][0]-self.pointSet[p2Key][0]\n",
    "        ydiff = self.pointSet[p1Key][1]-self.pointSet[p2Key][1]\n",
    "        distance = math.sqrt(xdiff**2 + ydiff**2)\n",
    "        return distance\n",
    "    \n",
    "    def getAllEdges(self):\n",
    "        #get all edges of point set\n",
    "        n=1\n",
    "        edges = []\n",
    "        for i in range (self.size()-1):\n",
    "            while n < self.size():\n",
    "                distance = self.euclidean_distance(i, n)\n",
    "                edges.append((distance, i, n))\n",
    "                n+=1\n",
    "            n=i+2   \n",
    "        return edges\n",
    "    \n",
    "    def size(self):\n",
    "        #get size of point set\n",
    "        return len(self.pointSet)\n",
    "\n",
    "#Function for generating random points with N is a user-definable parameter.\n",
    "def randomPoints(min_val, max_val, N):\n",
    "    \n",
    "    #initial Points class \n",
    "    points = Points() \n",
    "    x =random.sample(range(min_val , max_val), N)\n",
    "    y =random.sample(range(min_val , max_val), N)\n",
    "    point_list = list(zip(x, y))\n",
    "    #add all points to the Points class (points)\n",
    "    n = 0\n",
    "    for point in point_list:\n",
    "        points.addPoint(n, point)\n",
    "        n+=1\n",
    "    return points\n",
    "\n",
    "#Generate ramdom points as a sample by using function: randomPoints and class : Points\n",
    "sample = randomPoints(0,2000,100)\n",
    "\n",
    "#Return each points with its ID\n",
    "print ('Each points with its ID:')\n",
    "print (sample.getPointSet())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Implement an ADT class for Partition (union-find). It must support the operations for generating a new partition , for generating a new set within the partition, for merging two sets (union) and for finding a set to which an element belongs (find). Using the tree-based implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ADT class for Union-find\n",
    "class UnionFind:\n",
    "\n",
    "    def __init__(self):\n",
    "        #hold parent for node\n",
    "        self.parent = dict()\n",
    "        #hold rank for node\n",
    "        self.rank = dict()\n",
    "        #hold cluster\n",
    "        self.clusters = dict()\n",
    "        #hold final edges\n",
    "        self.finalEdges = []\n",
    "    \n",
    "    #\n",
    "    def makeSet(self,node):\n",
    "        \n",
    "        #set the nodes' parent to the node itself\n",
    "        self.parent[node] = node\n",
    "        #set initial rank of node to 0\n",
    "        self.rank[node] = 0\n",
    "        #add the node to cluster list\n",
    "        self.clusters[node] = set()\n",
    "        self.clusters[node].add(node) \n",
    "         \n",
    "    #union the nodeA and nodeB clusters\n",
    "    def union(self, nodeA, nodeB):\n",
    "        self.link(nodeA, nodeB)\n",
    "\n",
    "    #link the nodeA to nodeB based upon the rank of the tree in cluster \n",
    "    def link(self, nodeA, nodeB):\n",
    "        \n",
    "        if self.rank[nodeA] > self.rank[nodeB]:\n",
    "            #update nodeA cluster and \n",
    "            #remove the nodeB cluster from the cluster list, since it is merged with nodeA cluster   \n",
    "            self.clusters[nodeA].update(self.clusters[nodeB]) \n",
    "            self.clusters.pop(nodeB)\n",
    "            \n",
    "            #add edges for two merged nodes \n",
    "            self.finalEdges.append((nodeA,nodeB)) \n",
    "            #update node's parent\n",
    "            self.parent[nodeB] = nodeA\n",
    "            \n",
    "        else:\n",
    "            #update nodeB cluster and \n",
    "            #remove the nodeA cluster from the cluster list, since it is merged with nodeB cluster   \n",
    "            self.clusters[nodeB].update(self.clusters[nodeA]) \n",
    "            self.clusters.pop(nodeA)\n",
    "            \n",
    "            #add edges for two merged nodes \n",
    "            self.finalEdges.append((nodeB,nodeA))\n",
    "            #update node's parent\n",
    "            self.parent[nodeA] = nodeB\n",
    "          \n",
    "            #increade the rank of the cluster after merging the cluster\n",
    "            if self.rank[nodeA] == self.rank[nodeB]:\n",
    "                self.rank[nodeB] = self.rank[nodeB] + 1\n",
    "                \n",
    "    #find the leader node of cluster without path compression\n",
    "    def findRootWithOutPathCompression(self, node):\n",
    "        parent = self.parent[node]\n",
    "        if node != self.parent[node]:\n",
    "            parent = self.findRootWithOutPathCompression(self.parent[node])\n",
    "        return parent\n",
    "    \n",
    "    #find the leader node of cluster with path compression\n",
    "    def findRootWithPathCompression(self, node):\n",
    "        if node != self.parent[node]:\n",
    "            self.parent[node] = self.findRootWithPathCompression(self.parent[node])\n",
    "        return self.parent[node]\n",
    "\n",
    "    #get clusters\n",
    "    def getCluster(self):\n",
    "        return self.clusters\n",
    "    \n",
    "    #get cluster size\n",
    "    def clusterSize(self):\n",
    "        return len(self.clusters)\n",
    "    \n",
    "    #get final edges \n",
    "    def getFinalEdges(self):\n",
    "        return list(self.finalEdges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Using the UnionFind ADT and test data function to implement the clustering procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges in the minimum spanning tree:\n",
      "[(53, 35), (31, 19), (95, 80), (72, 14), (15, 9), (36, 18), (69, 22), (95, 73), (17, 10), (63, 62), (93, 44), (76, 46), (74, 28), (78, 70), (78, 34), (93, 41), (15, 86), (95, 48), (50, 4), (76, 52), (38, 6), (36, 82), (78, 79), (76, 21), (45, 0), (78, 38), (53, 31), (57, 33), (94, 64), (55, 13), (72, 57), (45, 89), (91, 27), (78, 69), (93, 15), (91, 63), (43, 11), (83, 77), (37, 16), (91, 39), (17, 12), (99, 32), (53, 72), (84, 75), (36, 25), (50, 47), (59, 5), (66, 24), (53, 96), (37, 20), (78, 71), (91, 76), (37, 58), (45, 8), (92, 49), (37, 50), (17, 2), (37, 65), (53, 7), (53, 85), (93, 36), (74, 23), (53, 43), (93, 98), (94, 51), (91, 66), (99, 74), (84, 61), (95, 67), (94, 26), (95, 30), (88, 60), (99, 37), (84, 1), (99, 88), (97, 42), (92, 95), (55, 29), (92, 90), (94, 87), (99, 91), (55, 68), (99, 17), (53, 54), (45, 59), (99, 81), (84, 3), (99, 93), (45, 83), (53, 99), (84, 55), (56, 40), (53, 45), (78, 97), (84, 94), (53, 78), (92, 84), (53, 92), (53, 56)]\n"
     ]
    }
   ],
   "source": [
    "#Kruskal’s algorithm with union-find for minimum spanning tree\n",
    "def kruskal(nodes,edges):\n",
    "    \n",
    "    #initial UnionFind\n",
    "    forest = UnionFind()\n",
    "    \n",
    "    #sort edges by distance from shortest to longest \n",
    "    edges.sort()\n",
    "    \n",
    "    #make points to forest as nodes in forest\n",
    "    for node in nodes:\n",
    "        forest.makeSet(node)\n",
    "    \n",
    "    #continuous union nodes in the forest from shortest distance\n",
    "    #of two nodes to reach a union cluster (a minimum spanning tree)\n",
    "    for edge in edges:\n",
    "        dist, nodeA, nodeB = edge\n",
    "        rootA = forest.findRootWithOutPathCompression(nodeA)\n",
    "        rootB = forest.findRootWithOutPathCompression(nodeB)\n",
    "        if rootA != rootB :   # in two different tree\n",
    "                forest.union(rootA, rootB)\n",
    "    \n",
    "    result = {}\n",
    "    result['finalEdges_list'] = forest.getFinalEdges()\n",
    "    return result\n",
    "\n",
    "#Run Kruskal For notes' minimum spanning tree\n",
    "runKruskalForPoints = kruskal(sample.getPointKeys(),sample.getAllEdges())\n",
    "#Print edges in the minimum spanning tree\n",
    "print ('Edges in the minimum spanning tree:')\n",
    "print (runKruskalForPoints['finalEdges_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bokeh to visualize the point sets, and the result of the minimum spanning tree\n",
    "x = [sample.getPointSet()[key][0] for key in sample.getPointSet()]\n",
    "y = [sample.getPointSet()[key][1] for key in sample.getPointSet()]\n",
    "point_df = pd.DataFrame( {'x': x, 'y': y})\n",
    "pp = Scatter(point_df, x = 'x', y = 'y', title='Minimum Spanning Tree')\n",
    "\n",
    "for edge in runKruskalForPoints['finalEdges_list']:\n",
    "    x1 = sample.getPoint(edge[0])[0]\n",
    "    x2 = sample.getPoint(edge[1])[0]\n",
    "    y1 = sample.getPoint(edge[0])[1]\n",
    "    y2 = sample.getPoint(edge[1])[1]\n",
    "    pp.line((x1,x2),(y1,y2), line_width=2)\n",
    "\n",
    "show(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='result_Minimum Spanning Tree.PNG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Extend forest-based UnionFind ADT class from above with path compression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#method of find root of node with path compression \n",
    "#method is in Union-find ADT class \n",
    "def findRootWithPathCompression(self, node):\n",
    "    if node != self.parent[node]:\n",
    "        self.parent[node] = self.findRootWithPathCompression(self.parent[node])\n",
    "    return self.parent[node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.  To find k-clusters  (implementation such that it stops when k clusters have been achieved and return those clusters, where k is a user-definable parameter.)\n",
    "\n",
    "Use hierarchical clustering by Agglomerative way, a bottom up approach that each point started as a cluster itself, and pairs of clusters are merged as one moves up the hierarchy from the shortest edge of two points till there are k cluster (in tree structure) remain to finish the clustering procedure. \n",
    "\n",
    "And merge the cluster by Single-link method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points ID in each Cluster:\n",
      "\n",
      "{0, 5, 8, 45, 77, 83, 89, 59}\n",
      "\n",
      "{2, 4, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 31, 32, 33, 35, 36, 37, 39, 41, 43, 44, 46, 47, 50, 52, 53, 54, 57, 58, 60, 62, 63, 65, 66, 72, 74, 76, 81, 82, 85, 86, 88, 91, 93, 96, 98, 99}\n",
      "\n",
      "{56, 40}\n",
      "\n",
      "{34, 69, 70, 38, 6, 71, 78, 79, 22}\n",
      "\n",
      "{1, 3, 68, 75, 13, 29, 84, 55, 61}\n",
      "\n",
      "{67, 73, 80, 90, 92, 30, 95, 48, 49}\n",
      "\n",
      "{64, 51, 87, 26, 94}\n",
      "\n",
      "{97, 42}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!!!Agglomerative hierarchical clustering by single-link \n",
    "def clustering(nodes,edges,k):\n",
    "    \n",
    "    #initial UnionFind\n",
    "    forest = UnionFind()\n",
    "    \n",
    "    #sort edges by distance from shortest to longest \n",
    "    edges.sort()\n",
    "        \n",
    "    #make points to forest as nodes in forest\n",
    "    for node in nodes:\n",
    "        forest.makeSet(node)\n",
    "        \n",
    "    #continuous union nodes in the forest from shortest distance of \n",
    "    #two nodes untill reach k clusters (number of k define by user)\n",
    "    for edge in edges:\n",
    "        dist, nodeA, nodeB = edge\n",
    "        rootA = forest.findRootWithPathCompression(nodeA)\n",
    "        rootB = forest.findRootWithPathCompression(nodeB)\n",
    "        if rootA != rootB :   # in two different tree\n",
    "                forest.union(rootA, rootB)\n",
    "                if forest.clusterSize() == k:\n",
    "                    clusters = forest.getCluster()\n",
    "                    break\n",
    "    \n",
    "    #define clusters_list to store clusters\n",
    "    clusters_list = []               \n",
    "    for key in clusters:\n",
    "        clusters_list.append(clusters[key])\n",
    "    \n",
    "    #define a dictionary to store information and class object of clustering for further usage and enquiries\n",
    "    result = {}\n",
    "    result['clusters_list'] = clusters_list\n",
    "    result['finalEdges_list'] = forest.getFinalEdges()\n",
    "    result['forest'] = forest\n",
    "    return result \n",
    "\n",
    "\n",
    "#Run clustering for sample points to k clusters (k is a user-definable parameter)\n",
    "#parameter: point set , points' edges , k (number of clusters for the point set)\n",
    "runClusteringForPoints = clustering(sample.getPointKeys(),sample.getAllEdges(),8)\n",
    "#print the clusters  \n",
    "print ('Points ID in each Cluster:')\n",
    "print ('')\n",
    "for cluster in runClusteringForPoints['clusters_list']:\n",
    "    print (cluster)\n",
    "    print ('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bokeh to visualize the point sets, and the result of clusters \n",
    "x = [sample.getPointSet()[key][0] for key in sample.getPointSet()]\n",
    "y = [sample.getPointSet()[key][1] for key in sample.getPointSet()]\n",
    "\n",
    "point_df = pd.DataFrame( {'x': 'x', 'y': 'y'})\n",
    "pp = Scatter(point_df, x = 'x', y = 'y', title='k-clusters')\n",
    "\n",
    "for edge in runClusteringForPoints['finalEdges_list']:\n",
    "    x1 = sample.getPoint(edge[0])[0]\n",
    "    x2 = sample.getPoint(edge[1])[0]\n",
    "    y1 = sample.getPoint(edge[0])[1]\n",
    "    y2 = sample.getPoint(edge[1])[1]\n",
    "    pp.line((x1,x2),(y1,y2), line_width=2)\n",
    "\n",
    "show(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='result_k-clusters.PNG'>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Implement functions/methods to let the user query whether two given points (nodes) belong to the same cluster (micro-grid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point 56 and point 67 is not in the same cluster.\n",
      "point 75 and point 55 is in the same cluster.\n"
     ]
    }
   ],
   "source": [
    "#Function for check if two nodes are in same cluster\n",
    "def checkTwoPoints(forest, nodeA, nodeB):\n",
    "    result= (forest.findRootWithPathCompression(nodeA) == forest.findRootWithPathCompression(nodeB))\n",
    "    if result == True:\n",
    "        return print ('point', nodeA, 'and point' , nodeB, 'is in the same cluster.')\n",
    "    else:\n",
    "        return print ('point', nodeA, 'and point' , nodeB, 'is not in the same cluster.')\n",
    "\n",
    "#Run function for checking if two points are in the same cluster\n",
    "#parameter: forest class object,  points 1 , point 2\n",
    "checkTwoPoints(runClusteringForPoints['forest'], 56 , 67 )\n",
    "checkTwoPoints(runClusteringForPoints['forest'], 75 , 55 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7. Define a function to compute the Dunn index, a measure for the quality of the clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn Index for the clustering is: 0.22537788284958593\n"
     ]
    }
   ],
   "source": [
    "#Function for Dunn index for the clustering \n",
    "def dunnIndex (clusters_list, sample):\n",
    "\n",
    "    #Find minimum of inter-Cluster Distance:\n",
    "    \n",
    "    #get clusters' centroids\n",
    "    centroids_list = []\n",
    "    for cluster in clusters_list:\n",
    "        x_list = [sample.getPoint(key)[0] for key in cluster]\n",
    "        y_list = [sample.getPoint(key)[1] for key in cluster]\n",
    "        centroid = sum(x_list)/len(cluster), sum(y_list)/len(cluster)\n",
    "        centroids_list.append((centroid))\n",
    "\n",
    "    #get all distrances of pair of two centroid \n",
    "    centroidsDistances_list = []\n",
    "    n=1\n",
    "    for i in range (len(centroids_list)-1):\n",
    "        while n < len(centroids_list):\n",
    "            xdiff = centroids_list[i][0]-centroids_list[n][0]\n",
    "            ydiff = centroids_list[i][1]-centroids_list[n][1]\n",
    "            distance = math.sqrt(xdiff**2 + ydiff**2)\n",
    "            centroidsDistances_list.append(distance)\n",
    "            n+=1\n",
    "        n=i+2\n",
    "        \n",
    "    min_interClusterDistance = min(centroidsDistances_list)\n",
    "    \n",
    "    #Find maximum of intra-Cluster Distance:\n",
    "    max_intraClusterDistance = 0\n",
    "    n=1\n",
    "    for cluster in clusters_list:\n",
    "        for i in range (len(clusters_list)-1): \n",
    "            while n < len(clusters_list):\n",
    "                max_intraClusterDistance = max(max_intraClusterDistance, sample.euclidean_distance(i,n))\n",
    "                n+=1\n",
    "            n=i+2\n",
    "    \n",
    "    #Get Dunn Index\n",
    "    dunnIndex = min_interClusterDistance/max_intraClusterDistance\n",
    "    return dunnIndex\n",
    "\n",
    "#Get the clusters list from the result of clustering \n",
    "clusters_list = runClusteringForPoints['clusters_list']\n",
    "#Run function to compute the Dunn index for the clustering \n",
    "dunnIndex = dunnIndex(clusters_list, sample)\n",
    "print ('Dunn Index for the clustering is:', dunnIndex )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Compare the forest that you have generated for the k-clustering to the full minimum cost spanning tree. Give a brief, but precise characterization of the sets of edges that are in the MCST but not in the forest of the -clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "In this hierarchical clustering, we use Agglomerative type, as a bottom up approach, for clustering that each point started as a cluster itself, and pairs of clusters are merged as one moves up the hierarchy from the shortest edge of two points till there are k cluster (in tree structure) remain to finish the clustering procedure.\n",
    "\n",
    "The different between the k-clustering and the full minimum cost spanning tree (MCST) is that the k-clustering is forest with k groups of tree while MCST have all points connected as a whole tree.\n",
    "\n",
    "So, for those edges that are only in the MCST, are all longer than edges exist in both k-clustering and MCST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Point (10%) Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Bokeh to visualize how the algorithm works \n",
    "#(i.e. visualize the point sets, the cluster connections as they emerge, and ultimately the results) \n",
    "x = [sample.getPointSet()[key][0] for key in sample.getPointSet()]\n",
    "y = [sample.getPointSet()[key][1] for key in sample.getPointSet()]\n",
    "\n",
    "point_df = pd.DataFrame( {'x': x, 'y': y})\n",
    "pp = Scatter(point_df, x = 'x', y = 'y', title='k-clusters')\n",
    "\n",
    "finalEdges_list = runClusteringForPoints['finalEdges_list']\n",
    "for edge in finalEdges_list:\n",
    "    x1 = sample.getPoint(edge[0])[0]\n",
    "    x2 = sample.getPoint(edge[1])[0]\n",
    "    y1 = sample.getPoint(edge[0])[1]\n",
    "    y2 = sample.getPoint(edge[1])[1]\n",
    "    pp.line((x1,x2),(y1,y2), line_width=2)\n",
    "\n",
    "show(pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='result_k-clusters.PNG'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
